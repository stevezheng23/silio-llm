name: silio-llm

conda_env: conda.yaml

entry_points:
  main:
    parameters:
      num_gpus: {type: int, default: 1}
      datastore_name: {type: str, default: ""}
      model_name_or_path: {type: str, default: "bert-base-uncased"}
      train_blob_path: {type: str, default: ""}
      train_file: {type: str, default: "train.json"}
      dev_blob_path: {type: str, default: ""}
      dev_file: {type: str, default: "dev.json"}
      test_blob_path: {type: str, default: ""}
      test_file: {type: str, default: "test.json"}
      label_blob_path: {type: str, default: ""}
      label_file: {type: str, default: "label.txt"}
      max_seq_length: {type: int, default: 128}
      batch_size: {type: int, default: 16}
      gradient_accumulation_steps: {type: int, default: 1}
      learning_rate: {type: float, default: 0.00003}
      num_epochs: {type: float, default: 3.0}
      weight_decay: {type: float, default: 0.01}
      warmup_steps: {type: int, default: 1000}
      eval_steps: {type: int, default: 500}
      output_dir: {type: str, default: "./output/"}
      seed: {type: int, default: 42}
      save_total_limit: {type: int, default: 10}
      registered_name: {type: str, default: ""}
    command: "sh ./script/run_seqcls.e2e.sh \
              --numgpus={num_gpus} \
              --randomseed={seed} \
              --dsname={datastore_name} \
              --trainblob={train_blob_path} \
              --trainfile={train_file} \
              --devblob={dev_blob_path} \
              --devfile={dev_file} \
              --testblob={test_blob_path} \
              --testfile={test_file} \
              --labelblob={label_blob_path} \
              --labelfile={label_file} \
              --outputdir={output_dir} \
              --modeldir={model_name_or_path} \
              --maxseqlen={max_seq_length} \
              --batchsize={batch_size} \
              --learningrate={learning_rate} \
              --numepochs={num_epochs} \
              --gradaccsteps={gradient_accumulation_steps} \
              --weightdecay={weight_decay} \
              --warmupsteps={warmup_steps} \
              --evalsteps={eval_steps} \
              --savelimit={save_total_limit} \
              --registeredname={registered_name}"
  seqcls_train:
    parameters:
      num_gpus: {type: int, default: 1}
      datastore_name: {type: str, default: ""}
      model_name_or_path: {type: str, default: "bert-base-uncased"}
      train_blob_path: {type: str, default: ""}
      train_file: {type: str, default: "train.json"}
      dev_blob_path: {type: str, default: ""}
      dev_file: {type: str, default: "dev.json"}
      test_blob_path: {type: str, default: ""}
      test_file: {type: str, default: "test.json"}
      label_blob_path: {type: str, default: ""}
      label_file: {type: str, default: "label.txt"}
      max_seq_length: {type: int, default: 128}
      batch_size: {type: int, default: 16}
      gradient_accumulation_steps: {type: int, default: 1}
      learning_rate: {type: float, default: 0.00003}
      num_epochs: {type: float, default: 3.0}
      weight_decay: {type: float, default: 0.01}
      warmup_steps: {type: int, default: 1000}
      eval_steps: {type: int, default: 500}
      output_dir: {type: str, default: "./output/"}
      seed: {type: int, default: 42}
      save_total_limit: {type: int, default: 10}
    command: "sh ./script/run_seqcls.train.sh \
              --numgpus={num_gpus} \
              --randomseed={seed} \
              --dsname={datastore_name} \
              --trainblob={train_blob_path} \
              --trainfile={train_file} \
              --devblob={dev_blob_path} \
              --devfile={dev_file} \
              --testblob={test_blob_path} \
              --testfile={test_file} \
              --labelblob={label_blob_path} \
              --labelfile={label_file} \
              --outputdir={output_dir} \
              --modeldir={model_name_or_path} \
              --maxseqlen={max_seq_length} \
              --batchsize={batch_size} \
              --learningrate={learning_rate} \
              --numepochs={num_epochs} \
              --gradaccsteps={gradient_accumulation_steps} \
              --weightdecay={weight_decay} \
              --warmupsteps={warmup_steps} \
              --evalsteps={eval_steps} \
              --savelimit={save_total_limit}"
  seqcls_eval:
    parameters:
      train_run_id: {type: str, default: ""}
      artifact_path: {type: str, default: ""}
      datastore_name: {type: str, default: ""}
      eval_blob_path: {type: str, default: ""}
      eval_file: {type: str, default: "eval.json"}
      label_blob_path: {type: str, default: ""}
      label_file: {type: str, default: "label.txt"}
      max_seq_length: {type: int, default: 128}
      batch_size: {type: int, default: 16}
    command: "sh ./script/run_seqcls.eval.sh \
              --runid={train_run_id} \
              --artifact={artifact_path} \
              --dsname={datastore_name} \
              --evalblob={eval_blob_path} \
              --evalfile={eval_file} \
              --labelblob={label_blob_path} \
              --labelfile={label_file} \
              --maxseqlen={max_seq_length} \
              --batchsize={batch_size}"
  seqcls_register:
    parameters:
      train_run_id: {type: str, default: ""}
      artifact_path: {type: str, default: ""}
      registered_name: {type: str, default: ""}
    command: "sh ./script/run_seqcls.register.sh \
              --runid={train_run_id} \
              --artifact={artifact_path} \
              --registeredname={registered_name}"
